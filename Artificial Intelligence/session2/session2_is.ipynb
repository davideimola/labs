{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-LAB SESSION 2: Informed search\n",
    "\n",
    "In the second session we will work on informed search\n",
    "\n",
    "## Maze environments\n",
    "\n",
    "The environments used are again **SmallMaze** (visible in the figure) and its variations\n",
    "![SmallMaze](images/maze.png)\n",
    "The agent starts in cell $(0, 2)$ and has to reach the treasure in $(4, 3)$\n",
    "\n",
    "## Priority Fringe\n",
    "\n",
    "You will need a queue ordered by priority as fringe, or **PriorityFringe**. The difference between the other versions of fringe is that in **PriorityFringe** nodes are removed from the fringe based on the current lowest value. In particular, **FringeNode** has two useful parameters (other than those used in the previous session):\n",
    "* *pathcost* - the path cost from the root node to the current one (defaults to 0)\n",
    "* *value* - value of a node. Used by **PriorityFringe** to order its content (defaults to 0)\n",
    "\n",
    "Here is an example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: 1\n",
      "Added: 2\n",
      "Added: 3\n",
      "Removed: 1\n",
      "Removed: 3\n",
      "Removed: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from utils.fringe import FringeNode, PriorityFringe\n",
    "\n",
    "# Create 3 nodes for state ids 1 2 3\n",
    "node_1 = FringeNode(1) # No parent, pathcost=0, value=0\n",
    "node_2 = FringeNode(2, node_1, node_1.pathcost + 1, 10) # Child of node_1, value=10\n",
    "node_3 = FringeNode(3, node_1, 100, 5)  # Child of node_1, pathcost=100, value=5\n",
    "\n",
    "p_fringe = PriorityFringe()\n",
    "for n in (node_1, node_2, node_3):\n",
    "    p_fringe.add(n)\n",
    "    print(\"Added: {}\".format(n.state))\n",
    "\n",
    "while not p_fringe.is_empty():\n",
    "    print(\"Removed: {}\".format(p_fringe.remove().state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the order in which nodes are removed from the fringe\n",
    "\n",
    "## Uniform-Cost Search (UCS)\n",
    "\n",
    "Before moving to informed search it is useful to see another uninformed search algorithm: the Uniform-Cost Search (UCS). In the following you can see the implementation in *tree search* version. Cost of performing an action is supposd to be 1 (also in the assignements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "Solution: [(0, 1), (1, 1), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import envs\n",
    "from utils.funcs import build_path\n",
    "\n",
    "\n",
    "def ucs(environment):\n",
    "    \"\"\"\n",
    "    Uniform-cost search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        path: solution as a path\n",
    "    \"\"\"\n",
    "    fringe = PriorityFringe()\n",
    "    fringe.add(FringeNode(environment.startstate))\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None\n",
    "        node = fringe.remove()  # Retrieve node from the fringe\n",
    "        if node.state == environment.goalstate:  # Goal state check\n",
    "            return build_path(node)\n",
    "        for action in range(environment.action_space.n):  # Look around\n",
    "            # Child node where value and pathcost are both the pathcost of parent + 1\n",
    "            child = FringeNode(environment.sample(node.state, action), node, node.pathcost + 1, node.pathcost + 1)\n",
    "            fringe.add(child)\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(\"SmallMaze-v0\")\n",
    "env.render()\n",
    "solution = ucs(env)\n",
    "\n",
    "# Print path\n",
    "print(\"\\nSolution: {}\".format([env.state_to_pos(s) for s in solution]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Heuristics\n",
    "\n",
    "Informed search requires a distance heuristic to be used in order to estimate the distance between a state and the goal. You already have at your disposal these functions:\n",
    "* *l1_norm(p1, p2)* - Computes the L1 norm (also known as the manhattan distance) between two points specified as tuples of coordinates\n",
    "* *l2_norm(p1, p2)* - Computes the L2 norm between two points specified as tuples of coordinates\n",
    "* *chebyshev(p1, p2)* - Computes the Chebyshev distance between two points specified as tuples of coordinates. Similar to L1 norm but diagonal moves are also considered\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm heuristic value: 6\n",
      "L2 norm heuristic value: 4.47213595499958\n",
      "Chebyshev heuristic value: 4\n"
     ]
    }
   ],
   "source": [
    "import utils.heuristics as heu\n",
    "\n",
    "p1 = (0, 2)\n",
    "p2 = (4, 0)\n",
    "print(\"L1 norm heuristic value: {}\".format(heu.l1_norm(p1, p2)))\n",
    "print(\"L2 norm heuristic value: {}\".format(heu.l2_norm(p1, p2)))\n",
    "print(\"Chebyshev heuristic value: {}\".format(heu.chebyshev(p1, p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "\n",
    "The first assignment is to implement the Greedy-best-first search algorithm on **SmallMaze**. In particular, you are required to implement both *greedy_tree_search* and *greedy_graph_search* versions that will be called by the generic *greedy*. Use *L1 norm* as heuristic function at first, then try also the others to see the differences.\n",
    "\n",
    "The results returned by *greedy* must be a tuple $(path, stats)$ in the following form:\n",
    "* *path* - tuple of state identifiers forming a path from the start state to the goal state. ``None`` if no solution is found\n",
    "* *stats* - tuple of:\n",
    "     * *time* - time elapsed between the start and the end of the algorithm\n",
    "     * *expc* - number of nodes explored. A node is considered as explored when removed from the fringe and analyzed\n",
    "     * *maxnodes* - maximum number of nodes in memory at the same time (fringe + closed)\n",
    "\n",
    "After the correctness of your implementations have been assessed, you can run the algorithms on other two maze environments: **GrdMaze** and **BlockedMaze**.\n",
    "\n",
    "The next two functions have to be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_tree_search(environment):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Tree search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    fringe = PriorityFringe()\n",
    "    fringe.add(FringeNode(environment.startstate))\n",
    "    exploredNodes = 0\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None, (0, 0)\n",
    "        node = fringe.remove()\n",
    "        exploredNodes = exploredNodes + 1\n",
    "        \n",
    "        if node.state == environment.goalstate:  # Goal state check\n",
    "            return build_path(node), (exploredNodes, exploredNodes + 1)\n",
    "        \n",
    "        for action in range(environment.action_space.n):  # Look around\n",
    "            nextNode = environment.sample(node.state, action)\n",
    "            child = FringeNode(nextNode, node, node.pathcost + 1, heu.l1_norm(nextNode, environment.goalstate))\n",
    "            fringe.add(child)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_graph_search(environment):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Graph search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    fringe = PriorityFringe()\n",
    "    closed = PriorityFringe() \n",
    "    fringe.add(FringeNode(environment.startstate))\n",
    "    exploredNodes = 1\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None, (0, 0)\n",
    "        node = fringe.remove()\n",
    "        exploredNodes = exploredNodes + 1\n",
    "        closed.add(node)\n",
    "        \n",
    "        for action in range(environment.action_space.n):  # Look around\n",
    "            nextNode = environment.sample(node.state, action)\n",
    "            child = FringeNode(nextNode, node, node.pathcost + 1, heu.l1_norm(nextNode, environment.goalstate))\n",
    "            \n",
    "            if child.state not in fringe and child.state not in closed:\n",
    "                if child.state == environment.goalstate:  # Goal state check\n",
    "                    return build_path(child), (exploredNodes, exploredNodes + 1)\n",
    "                exploredNodes = exploredNodes + 1\n",
    "                fringe.add(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(environment, search_type):\n",
    "    \"\"\"\n",
    "    Greedy-best-first search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        search_type: type of search - greedy_tree_search or greedy_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (time, expc, maxnodes): elapsed time, number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    t = timer()\n",
    "    path, stats = search_type(environment)\n",
    "    return path, (timer() - t, stats[0], stats[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calls your tree search version of Greedy-best-first search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envname = \"SmallMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tTREE SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = greedy(env, greedy_tree_search)  # Perform Greedy-best-first search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for Greedy-best-first tree search can be found [here](results/greedy_tree_search_results.txt)\n",
    "\n",
    "The following code calls your graph search version of Greedy-best-first search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tGRAPH SEARCH\n",
      "\tEnvironment:  SmallMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "\n",
      "Execution time: 0.0063s\n",
      "N° of nodes explored: 25\n",
      "Max n° of nodes in memory: 26\n",
      "Solution: [(0, 3), (1, 3), (2, 3), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tGRAPH SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = greedy(env, greedy_graph_search)  # Perform Greedy-best-first search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for Greedy-best-first graph search can be found [here](results/greedy_graph_search_results.txt)\n",
    "\n",
    "## Assignment 2\n",
    "\n",
    "The second assignment is to implement the A* search algorithm on **SmallMaze**. In particular, you are required to implement both *astar_tree_search* and *astar_graph_search* versions that will be called by the generic *astar*. Use *L1 norm* as heuristic function at first, then try also the others to see the differences.\n",
    "\n",
    "The results returned by *astar* must be a tuple $(path, stats)$ in the following form:\n",
    "* *path* - tuple of state identifiers forming a path from the start state to the goal state. ``None`` if no solution is found\n",
    "* *stats* - tuple of:\n",
    "     * *time* - time elapsed between the start and the end of the algorithm\n",
    "     * *expc* - number of nodes explored. A node is considered as explored when removed from the fringe and analyzed\n",
    "     * *maxnodes* - maximum number of nodes in memory at the same time (fringe + closed)\n",
    "\n",
    "After the correctness of your implementations have been assessed, you can run the algorithms on other two maze environments: **GrdMaze** and **BlockedMaze**.\n",
    "\n",
    "The next two functions have to be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_tree_search(environment):\n",
    "    \"\"\"\n",
    "    A* Tree search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    fringe = PriorityFringe()\n",
    "    fringe.add(FringeNode(environment.startstate))\n",
    "    exploredNodes = 1\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None, (0, 0)\n",
    "        node = fringe.remove()\n",
    "        exploredNodes = exploredNodes + 1\n",
    "        \n",
    "        if node.state == environment.goalstate:  # Goal state check\n",
    "            return build_path(node), (exploredNodes, exploredNodes + 1)\n",
    "        \n",
    "        for action in environment.actions:  # Look around\n",
    "            nextNode = environment.sample(node.state, action)\n",
    "            child = FringeNode(nextNode, node, node.pathcost + 1, node.pathcost + heu.l1_norm(nextNode, environment.goalstate) + 1)\n",
    "            exploredNodes = exploredNodes + 1\n",
    "            fringe.add(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_graph_search(environment):\n",
    "    \"\"\"\n",
    "    A* Graph search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    fringe = PriorityFringe()\n",
    "    closed = PriorityFringe() \n",
    "    fringe.add(FringeNode(environment.startstate))\n",
    "    exploredNodes = 1\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None, (0, 0)\n",
    "        node = fringe.remove()\n",
    "        exploredNodes = exploredNodes + 1\n",
    "        closed.add(node)\n",
    "        \n",
    "        for action in environment.actions:  # Look around\n",
    "            nextNode = environment.sample(node.state, action)\n",
    "            child = FringeNode(nextNode, node, node.pathcost + 1, node.pathcost + heu.l1_norm(nextNode, environment.goalstate) + 1)\n",
    "            \n",
    "            if child.state not in fringe and child.state not in closed:\n",
    "                if child.state == environment.goalstate:  # Goal state check\n",
    "                    return build_path(child), (exploredNodes, exploredNodes + 1)\n",
    "                exploredNodes = exploredNodes + 1\n",
    "                fringe.add(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(environment, search_type):\n",
    "    \"\"\"\n",
    "    A* search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        search_type: type of search - astar_tree_search or astar_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (time, expc, maxnodes): elapsed time, number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    t = timer()\n",
    "    path, stats = search_type(environment)\n",
    "    return path, (timer() - t, stats[0], stats[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calls your tree search version of A* search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tTREE SEARCH\n",
      "\tEnvironment:  GrdMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'C' 'S']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "\n",
      "Execution time: 0.3955s\n",
      "N° of nodes explored: 9752\n",
      "Max n° of nodes in memory: 9753\n",
      "Solution: [(1, 3), (2, 3), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "envname = \"GrdMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tTREE SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = astar(env, astar_tree_search)  # Perform A* search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for A* tree search can be found [here](results/astar_tree_search_results.txt)\n",
    "\n",
    "The following code calls your graph search version of A* search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tGRAPH SEARCH\n",
      "\tEnvironment:  GrdMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'C' 'S']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "\n",
      "Execution time: 0.0048s\n",
      "N° of nodes explored: 23\n",
      "Max n° of nodes in memory: 24\n",
      "Solution: [(1, 3), (2, 3), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "envname = \"GrdMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tGRAPH SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = astar(env, astar_graph_search)  # Perform A* search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for A* graph search can be found [here](results/astar_graph_search_results.txt)\n",
    "\n",
    "## Discussion\n",
    "\n",
    "Now that you have correctly implemented both Greedy-best-first and A* what can you say about the solutions they compute? Are there significant differences in the stats? Try to play with other heuristics as well and see if your results change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
